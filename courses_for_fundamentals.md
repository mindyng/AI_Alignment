* [What Eval org, Apollo Reasearch, is looking for](https://jobs.lever.co/apolloresearch/f66ef22f-f96a-42cb-ada9-fd48ce0d5fda)

* [ ] from Industry expert-OpenAI co-founder, [Andrej Karpathy, Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI) (how these are actually built, will help with pre, in- and post- processing of LLM's, what goes into prompt box, what is inside model, generation of response text)

* [ ] [AI Safety Fundamentals](https://course.aisafetyfundamentals.com/alignment?session=1)
* [ ] [Stanford - Intro to AI Alignment](https://docs.google.com/document/d/1NX0DlZRzD3NP7tBeLjMh76w7-w2s8SxV3wj0P7EYpKY/edit?tab=t.0#heading=h.4p5dmkpp2yu9)
* [ ] [How to Get Started in Alignment](https://www.alignmentforum.org/posts/PqMT9zGrNsGJNfiFR/alignment-research-field-guide)
  * [Author with LI connections to reach out to](https://www.linkedin.com/in/wentworthjohn/)
* [ ] [How to Get Into Independent Research on Alignment/Agency](https://www.lesswrong.com/posts/P3Yt66Wh5g7SbkKuT/how-to-get-into-independent-research-on-alignment-agency)
* [ ] [Code Implementation of LLM Guardrail](https://github.com/mindyng/GuardReasoner)
