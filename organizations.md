* [Anthropic Research Team: Societal Impact, Alignment, Interpretability](https://www.anthropic.com/research)
* [Center for AI Safety](https://www.safe.ai/careers)
* [Future of Life Institute](https://futureoflife.org/)
* [Alignment Research Center](https://www.alignment.org/)
* Practically Seeing the Reason Why by Jail Breaking with [Gray Swan Arena](https://app.grayswan.ai/arena)
* [Machine Intelligence Research Institute](https://intelligence.org/get-involved/)
* [Special Competitive Studies Project](https://www.scsp.ai/)
* [80,000 Hours](https://80000hours.org)
  * https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/
  * https://80000hours.org/problem-profiles/artificial-intelligence/
  * https://80000hours.org/articles/ai-policy-guide/
* [Open Philanthropy](https://www.openphilanthropy.org/)
* [Center for Humane Technology](https://www.humanetech.com/)
* [Foresight Institute](https://foresight.org/technologies/secure-ai/)
* [Center for Human-Compatible AI](https://humancompatible.ai/about/)
* [FAR AI](https://www.youtube.com/@FARAIResearch/videos)

* [aisafety.com - All I needed](https://www.aisafety.com/map)
