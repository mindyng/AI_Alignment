* [University of Waterloo, School of Comp Sci Guide](https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf)
* Applying it on this Paper: [A Survey on Evaluation of Large Language Models](https://arxiv.org/pdf/2307.03109)

First pass should take about five to ten minutes and consists of the following steps:
1. Carefully read the title, abstract, and introduction
2. Read the section and sub-section headings, but ignore
everything else
3. Read the conclusions
4. Glance over the references, mentally ticking off the
ones you’ve already read

At the end of the first pass, you should be able to answer
the five Cs:
1. Category: What type of paper is this? A measurement paper? An analysis of an existing system? A
description of a research prototype?
2. Context: Which other papers is it related to? Which
theoretical bases were used to analyze the problem?
3. Correctness: Do the assumptions appear to be valid?
4. Contributions: What are the paper’s main contributions?
5. Clarity: Is the paper well written?

Second pass involves reading the paper with greater care, but ignore details such as proofs. Jot down the key
points or to make comments in the margins:
1. Look carefully at the figures, diagrams and other illustrations in the paper. Pay special attention to graphs.
Are the axes properly labeled? Are results shown with
error bars, so that conclusions are statistically significant? Common mistakes like these will separate
rushed, shoddy work from the truly excellent.
2. Remember to mark relevant unread references for further reading (this is a good way to learn more about
the background of the paper).

At this point, should be able to understand the main purpose of the paper with supporting evidence. At this point, reading suffices interest, but not for those seeking deeper insight into research speciality.

Third pass involves _virtually reimplementing the paper_ . 
* will discover innovations and also short-comings (failings in assumptions and execution)
* challenge every assumption
* think about being the original author and how you would present research topic
* can add this to repretoire of tools for future work
* at the end, should be able to recite paper's structure from memory
* be able to identify issues with experiment or analysis too

___

* [Stanford CS230: Deep Learning | Autumn 2018 | Lecture 8 - Career Advice / Reading Research Papers | Prod. Andrew Ng](https://www.youtube.com/watch?v=733m6qBH-jI)
### area want to be good at (e.g. mech interp/LLM evals/CoT)
* compile list of papers (research papers on Archiv, Medium posts, rare GitHub), start with 5 papers, skipping around a list
read 10% (paper #2 is dud -> forget it). Paper #3 is similar and spend lot of time to read and understand (6 citations) and flush out idea of paper 4...
* 15-20 papers- basic understanding of body- apply some algo; 50-100 papers- very good understanding of subject- enough to implement maybe not enough for research/innovation
* how to read 1 paper:
** don't go from first word to last word
** multiple passes through paper
  1. read title, abstract, figures (whole paper summarized here)
  2. intro, conclusions, figures again carefully, skim the rest; when publishing (convincing reviewers worthy of acceptance; abstract to make case why to accept for pub)
  3. related works (skim/skip unless already familiar with body of lit; almost impossible to understand, usually trying to stuff all the papers from reviewers)
  4. read the paper- skip the math
  5. read the whole thing, but skip parts that don't make sense
* what did authors try to accomplish?
* what were the key elements?
* what can I use myself?
* what other ref's do you want to follow?

## Math
* put aside results and re-derive from scratch - blank piece of paper
* ability to generalize to derive new novel algo's
* art galleries (students copying art work of masters); good at match, good way to do it

## Code
* dl and run open-source code
* re-implement it from scratch

## Longer-Term Advice
* learn steadily; not focused intense activity; well-known from pedagogy; solid result- space repetition; better long-term attn

-- sources for papers: Twitter, ML subreddit (lot of noise), NIPS, ICML, ICLR, like-minded people
