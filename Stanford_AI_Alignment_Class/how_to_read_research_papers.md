Reference: [Stanford CS230: Deep Learning | Autumn 2018 | Lecture 8 - Career Advice / Reading Research Papers | Prod. Andrew Ng](https://www.youtube.com/watch?v=733m6qBH-jI)
### area want to be good at (e.g. mech interp/LLM evals/CoT)
* compile list of papers (research papers on Archiv, Medium posts, rare GitHub), start with 5 papers, skipping around a list
read 10% (paper #2 is dud -> forget it). Paper #3 is similar and spend lot of time to read and understand (6 citations) and flush out idea of paper 4...
* 15-20 papers- basic understanding of body- apply some algo; 50-100 papers- very good understanding of subject- enough to implement maybe not enough for research/innovation
* how to read 1 paper:
** don't go from first word to last word
** multiple passes through paper
  1. read title, abstract, figures (whole paper summarized here)
  2. intro, conclusions, figures again carefully, skim the rest; when publishing (convincing reviewers worthy of acceptance; abstract to make case why to accept for pub)
  3. related works (skim/skip unless already familiar with body of lit; almost impossible to understand, usually trying to stuff all the papers from reviewers)
  4. read the paper- skip the math
  5. read the whole thing, but skip parts that don't make sense
* what did authors try to accomplish?
* what were the key elements?
* what can I use myself?
* what other ref's do you want to follow?

## Math
* put aside results and re-derive from scratch - blank piece of paper
* ability to generalize to derive new novel algo's
* art galleries (students copying art work of masters); good at match, good way to do it

## Code
* dl and run open-source code
* re-implement it from scratch

## Longer-Term Advice
* learn steadily; not focused intense activity; well-known from pedagogy; solid result- space repetition; better long-term attn

-- sources of papers: Twitter, ML subreddit (lot of noise), NIPS, ICML, ICLR, like-minded 
