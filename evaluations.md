* cool [LLM Eval tool](https://eugeneyan.com/writing/llm-evaluators/) based off of [Anthropic paper: Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)
* famous paper: ["A Survey on Evaluation of Large Language Models"](https://arxiv.org/abs/2307.03109) [repo](https://github.com/MLGroupJLU/LLM-eval-survey)
* [HuggingFace Eval Guide](https://github.com/huggingface/evaluation-guidebook)
* what needs to be evaluated - [OpenAI's model spec](https://model-spec.openai.com/2025-02-12.html), which includes Stay in Bounds
